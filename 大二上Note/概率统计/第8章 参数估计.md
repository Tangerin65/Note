通过不构造统计量，把未知参数的信息集中到一起
# 点估计
就是用一个样本中计算出来的单一数值，去猜测（或估计）总体中那个未知参数的真实值$\theta$
### 1.矩估计法
 - 文字定义/计算方法：[[Chapter8教材.pdf#page=2&selection=10,0,18,4&color=yellow|Chapter8教材, p.2]][[Chapter8教材.pdf#page=2&selection=20,0,46,5&color=yellow|Chapter8教材, p.2]]
	简单来说，就是认为：
		用样本均值估计总体均值
		用样本方差估计总体方差
		计算含有$\theta$参数的总体均值/方差，反解出$\theta$，用样本均值/方差代替总体均值/方差，即可完成估计
 - 例题：[[Chapter8教材.pdf#page=2&selection=126,0,127,3&color=note|Chapter8教材, p.2]]
 - 题目里一定会明说用矩估计
 - P.S.矩估计量可以不唯一
 - 对多个位置参数(一般最多2个)：采用$X^i$的方式联立方程反解位置参数![[Chapter8教材.pdf#page=3&rect=23,296,410,400&color=note|Chapter8教材, p.3]]
	 不一定非得全是$E(X)$，$D(X)$也行
 - 二级结论：![[Pasted image 20251201092905.png]]
	$B^2$是什么：[[第7章 统计量和抽样分布定理#^e17b1c]]

### 2.极大似然估计
 - 基本思想：已发生事件是概率最大的，利用这个事件作为已知条件，去逆向推导出最能解释它发生的那个模型参数$\theta$[[Chapter8教材.pdf#page=6&selection=196,0,214,3&color=yellow|Chapter8教材, p.6]]
 - 似然函数：出现某种观测值的概率[[Chapter8教材.pdf#page=6&selection=179,0,195,2&color=yellow|Chapter8教材, p.6]]
	 - 离散型随机变量计算方法：观测值代入后分布律的乘积
	 - 连续型随机变量计算方法：观测值代入后密度函数的乘积[[Chapter8教材.pdf#page=7&selection=109,3,117,8&color=yellow|Chapter8教材, p.7]]
 - 极大似然估计值/量：[[Chapter8教材.pdf#page=7&selection=203,0,229,8&color=yellow|Chapter8教材, p.7]]
	 - 取到似然函数最大值的参数$\theta$
	 - 求最大值点->求这个值可以通过求导=0方程解决[[Chapter8教材.pdf#page=7&selection=238,1,241,2&color=yellow|Chapter8教材, p.7]]
	 - 为了简化计算->给似然函数取对数再求导=0[[Chapter8教材.pdf#page=7&selection=267,0,270,2&color=yellow|Chapter8教材, p.7]]
	 - **有解**：总体服从单峰分布有解->**只有均匀分布无解**[[第8章 参数估计#^03bb50]]
	 - 值和量的区别：估计值针对样本观测值$x$，估计量针对整体$X$
 - 多个未知参数${\theta}_i$的似然估计：整个似然方程取对数后分别对每个未知参数求导=0，解开这多个方程即可。从考试难度考虑，这种情况下肯定是有解的[[Chapter8教材.pdf#page=10&selection=198,0,206,11&color=yellow|Chapter8教材, p.10]]
 - if似然方程无解(均匀分布)：^444 ^03bb50[[Chapter8教材.pdf#page=12&selection=1,0,23,2&color=yellow|Chapter8教材, p.12]]
	 - 解决方案：画图[[Chapter8教材.pdf#page=12&selection=100,0,105,3&color=yellow|Chapter8教材, p.12]]
		 - 具体理解过程：以$\theta>0$，导数<0为例![[Pasted image 20251203172422.png]]
			 - $\theta<0$时$\frac{dL(\theta)}{d(\theta)}$<0，后续操作如图。如果$\frac{dL(\theta)}{d(\theta)}>0$就反过来
### 3.估计量的评选标准
一般考前面两个
#### 3.1.无偏性标准
 - 本质就是算期望
 - 如何计算偏差：$b(\hat{\theta})=E(\hat{\theta})-\theta$     [[Chapter8教材.pdf#page=12&selection=187,0,195,1&color=yellow|Chapter8教材, p.12]]
	 - 无偏估计量[[Chapter8教材.pdf#page=12&selection=177,1,177,6&color=yellow|p.12]]/渐进无偏估计量[[Chapter8教材.pdf#page=12&selection=222,1,224,2&color=yellow|p.12]]
	 - 这也就是算方差要除$n-1$的原因 ^98ygt8  ^d55c38
#### 3.2.有效性标准
 - 本质就是算方差
 - 只能在**无偏估计量**上使用
 - 如何计算有效性：$D(\hat{\theta_1})≤D(\hat{\theta_2})$->前者更有效(方差更小的那个更有效)[[Chapter8教材.pdf#page=14&selection=2,4,4,1&color=yellow|p.14]]
#### 3.3.一致性标准
 - 基本不考(和无偏性标准重叠)
 - 本质还是算期望(辛钦大数定律)
 - 若估计量$\hat{\theta_n}$依概率收敛到$\theta$，则前者是后者的一致估计量[[Chapter8教材.pdf#page=15&selection=5,0,12,6&color=yellow|p.15]]
#### 3.4.均方误差标准
 - 基本不考(计算量太大)
 - 均方误差：$E(\hat{\theta}-\theta)^2=D(\hat{\theta})+[E(\hat{\theta})-\theta]$
 - 均方误差更小者更有效[[Chapter8教材.pdf#page=15&selection=191,0,191,15&color=yellow|p.15]]
4
